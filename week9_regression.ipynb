{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3f021f-d678-40ae-b791-5aa2aff1a4e7",
   "metadata": {},
   "source": [
    "<h2> Exploring linear regression </h2>\n",
    "\n",
    "In class, we've found that one of the ways that we can build a model for data is via least squares linear regression. Given a set of data points $(x_i, y_i)$, we build a line $y = \\alpha + \\beta x$ where\n",
    "$$\\beta = \\frac{n \\sum x_i y_i - \\left(\\sum x_i\\right)\\left(\\sum y_i\\right)}{n \\sum x_i^2 - \\left(\\sum x_i\\right)^2}$$\n",
    "and\n",
    "$$\\alpha = \\overline{y}_n - \\beta \\overline{x}_n.$$\n",
    "But how do we assess whether a linear model is actually a good fit for given data? There are [many ways to do this](https://en.wikipedia.org/wiki/Goodness_of_fit), including by computing correlation coefficients.\n",
    "\n",
    "<h4> Determining if a linear model is appropriate </h4>\n",
    "\n",
    "You're given two files with data in them; one of them comes from a linear model (plus random noise) and the other one comes from a non-linear model.\n",
    "\n",
    "**Question**: For each data set:\n",
    "\n",
    "* Compute the least squares regression line.\n",
    "* Find the sum of squares of the residuals for your model.\n",
    "\n",
    "The data sets are in the lists `data1` and `data2`. The code below imports the data (it's a list of pairs of data, which are $x_i$ and $y_i$ respectively), but you'll need to compute the regression coefficients. Both data sets have `n=100` data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5d9f282-72e2-4248-8724-0d16084b0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [[21.26, 11.71], [90.37, 204.32], [12.72, 4.33], [36.29, 33.47], [40.39, 41.38], [97.26, 237.09], [96.86, 236.82], [30.49, 23.4], [40.43, 41.43], [65.18, 106.41], [96.99, 235.92], [83.04, 174.19], [44.81, 50.88], [40.29, 41.58], [9.76, 2.57], [17.09, 7.32], [41.95, 44.52], [14.54, 5.53], [8.02, 1.8], [15.41, 6.13], [4.18, 0.45], [30.9, 24.63], [87.49, 193.11], [33.56, 28.26], [3.41, 0.33], [88.13, 195.67], [87.44, 191.47], [78.25, 154.56], [21.48, 11.7], [23.67, 14.26], [74.53, 140.62], [13.29, 4.71], [36.41, 33.89], [62.35, 97.63], [82.29, 171.29], [50.27, 64.39], [25.04, 15.94], [60.42, 92.77], [53.55, 72.67], [84.92, 182.28], [14.46, 5.44], [76.58, 148.25], [32.49, 26.62], [88.68, 197.66], [7.31, 1.38], [12.87, 4.16], [60.71, 92.58], [75.7, 143.55], [66.44, 111.64], [7.08, 1.37], [89.1, 199.28], [51.68, 68.02], [3.24, 0.33], [72.17, 131.62], [15.21, 6.12], [18.35, 8.79], [50.97, 65.68], [49.52, 62.22], [5.1, 0.69], [71.93, 129.89], [30.79, 23.95], [49.46, 62.05], [1.1400000000000001, 0.03], [53.03, 71.2], [44.44, 50.38], [43.5, 48.19], [68.42, 117.48], [27.2, 18.74], [83.92, 177.43], [96.96, 236.95], [88.2, 196.43], [96.64, 235.26], [15.18, 5.82], [64.14, 104.28], [66.55, 111.16], [58.01, 85.25], [52.41, 69.34], [16.18, 6.84], [21.21, 11.39], [79.58, 158.77], [90.25, 204.57], [80.68, 164.16], [1.2, 0.05], [51.68, 66.85], [35.57, 31.99], [75.97, 145.25], [44.47, 50.15], [65.33, 107.87], [1.88, 0.09], [98.46, 244.46], [60.51, 92.37], [40.7, 41.93], [54.25, 74.07], [96.67, 234.51], [8.26, 1.82], [89.55, 201.92], [78.5, 155.05], [44.94, 51.59], [14.22, 5.2], [41.5, 44.04]]\n",
    "data2 = [[21.26, 59.92], [90.37, 281.17], [12.72, 33.44], [36.29, 109.08], [40.39, 122.47], [97.26, 302.95], [96.86, 301.99], [30.49, 90.24], [40.43, 121.36], [65.18, 201.53], [96.99, 302.52], [83.04, 259.03], [44.81, 135.94], [40.29, 122.05], [9.76, 24.19], [17.09, 47.83], [41.95, 125.92], [14.54, 39.67], [8.02, 17.4], [15.41, 42.25], [4.18, 5.4], [30.9, 91.86], [87.49, 272.19], [33.56, 100.2], [3.41, 2.89], [88.13, 275.23], [87.44, 271.52], [78.25, 243.87], [21.48, 61.07], [23.67, 68.24], [74.53, 231.38], [13.29, 35.05], [36.41, 109.36], [62.35, 192.53], [82.29, 255.18], [50.27, 154.15], [25.04, 73.47], [60.42, 186.86], [53.55, 164.19], [84.92, 264.2], [14.46, 38.66], [76.58, 237.89], [32.49, 97.46], [88.68, 276.41], [7.31, 15.69], [12.87, 33.91], [60.71, 186.76], [75.7, 235.29], [66.44, 204.98], [7.08, 15.71], [89.1, 277.09], [51.68, 158.76], [3.24, 3.96], [72.17, 223.11], [15.21, 40.69], [18.35, 51.39], [50.97, 154.73], [49.52, 151.2], [5.1, 7.92], [71.93, 223.62], [30.79, 91.91], [49.46, 151.36], [1.1400000000000001, -3.7], [53.03, 162.44], [44.44, 134.58], [43.5, 132.64], [68.42, 211.23], [27.2, 80.45], [83.92, 260.28], [96.96, 302.68], [88.2, 274.69], [96.64, 301.17], [15.18, 40.66], [64.14, 198.5], [66.55, 205.6], [58.01, 177.35], [52.41, 159.51], [16.18, 44.4], [21.21, 60.2], [79.58, 247.98], [90.25, 281.13], [80.68, 250.47], [1.2, -3.04], [51.68, 157.77], [35.57, 105.78], [75.97, 235.57], [44.47, 135.71], [65.33, 202.2], [1.88, -0.76], [98.46, 307.29], [60.51, 186.06], [40.7, 123.18], [54.25, 165.69], [96.67, 302.68], [8.26, 19.44], [89.55, 278.2], [78.5, 244.44], [44.94, 135.95], [14.22, 38.39], [41.5, 126.2]]\n",
    "\n",
    "n = 100\n",
    "\n",
    "# Get the first set of X and Y coordinates from data1\n",
    "X = [d[0] for d in data1]\n",
    "Y = [d[1] for d in data1]\n",
    "\n",
    "# Compute E[X] and E[Y]\n",
    "e_x = sum(X) / n\n",
    "e_y = sum(Y) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671bfaf-4e80-4d66-9a7b-1198f4a421b5",
   "metadata": {},
   "source": [
    "<h4> Training data and validation data </h4>\n",
    "\n",
    "Another way to assess whether (any) model is a good fit is to split the data into a mix of *training data* (which is used to build the model) and *validation data* (which is used to check it). We can implement this too, using the following process:\n",
    "\n",
    "* Randomly split our data into $50$ training points and $50$ validation points.\n",
    "* Build the least squares regression model with the $50$ training points.\n",
    "* Compute the sum of squares of the residuals *only* for the $50$ validation points.\n",
    "* Assess whether the error is acceptable or not.\n",
    "\n",
    "**Question:** Implement this for the same two data sets. For the training data, take the first $50$ points (the $x$-values were already randomized -- otherwise this is a really bad idea!). The validation data are the remaining $50$ data points. Which one seems to be a better fit for a linear model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42d4fbd-1d5c-4999-b7fb-abcfcf3f8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad6c41d-4fff-4779-9b4a-8c626abe5953",
   "metadata": {},
   "source": [
    "<h4> Extra question (Optional) </h4>\n",
    "\n",
    "Plot the data (look at the some of the class-demo notebooks for how to code this!). Does the graph match your answers from the previous questions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
